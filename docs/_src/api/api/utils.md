<a id="export_utils"></a>

# Module export\_utils

<a id="export_utils.print_answers"></a>

#### print\_answers

```python
def print_answers(results: dict, details: str = "all", max_text_len: Optional[int] = None)
```

Utility function to print results of Haystack pipelines

**Arguments**:

- `results`: Results from a pipeline
- `details`: One of "minimum", "medium", "all". Defining the level of details to print.
- `max_text_len`: shorten lengthy text fields to the maximum allowed length. Set to
None to not cut long text.

**Returns**:

None

<a id="export_utils.print_documents"></a>

#### print\_documents

```python
def print_documents(results: dict, max_text_len: Optional[int] = None, print_name: bool = True, print_meta: bool = False)
```

Utility that prints a compressed representation of the documents returned by a pipeline.

**Arguments**:

- `max_text_lenght`: shorten the document's content to a maximum number of chars. if None, does not cut.
- `print_name`: whether to print the document's name (from the metadata) or not.
- `print_meta`: whether to print the document's metadata or not.

<a id="export_utils.print_questions"></a>

#### print\_questions

```python
def print_questions(results: dict)
```

Utility to print the output of a question generating pipeline in a readable format.

<a id="export_utils.export_answers_to_csv"></a>

#### export\_answers\_to\_csv

```python
def export_answers_to_csv(agg_results: list, output_file)
```

Exports answers coming from finder.get_answers() to a CSV file

**Arguments**:

- `agg_results`: list of predictions coming from finder.get_answers()
- `output_file`: filename of output file

**Returns**:

None

<a id="export_utils.convert_labels_to_squad"></a>

#### convert\_labels\_to\_squad

```python
def convert_labels_to_squad(labels_file: str)
```

Convert the export from the labeling UI to SQuAD format for training.

**Arguments**:

- `labels_file`: path for export file from the labeling tool

<a id="preprocessing"></a>

# Module preprocessing

<a id="preprocessing.convert_files_to_docs"></a>

#### convert\_files\_to\_docs

```python
def convert_files_to_docs(dir_path: str, clean_func: Optional[Callable] = None, split_paragraphs: bool = False, encoding: Optional[str] = None, id_hash_keys: Optional[List[str]] = None) -> List[Document]
```

Convert all files(.txt, .pdf, .docx) in the sub-directories of the given path to Documents that can be written to a

Document Store.

**Arguments**:

- `dir_path`: path for the documents to be written to the DocumentStore
- `clean_func`: a custom cleaning function that gets applied to each doc (input: str, output:str)
- `split_paragraphs`: split text in paragraphs.
- `encoding`: character encoding to use when converting pdf documents.
- `id_hash_keys`: Generate the document id from a custom list of strings that refer to the document's
attributes. If you want to ensure you don't have duplicate documents in your DocumentStore but texts are
not unique, you can modify the metadata and pass e.g. `"meta"` to this field (e.g. [`"content"`, `"meta"`]).
In this case the id will be generated by using the content and the defined metadata.

<a id="preprocessing.tika_convert_files_to_docs"></a>

#### tika\_convert\_files\_to\_docs

```python
def tika_convert_files_to_docs(dir_path: str, clean_func: Optional[Callable] = None, split_paragraphs: bool = False, merge_short: bool = True, merge_lowercase: bool = True, id_hash_keys: Optional[List[str]] = None) -> List[Document]
```

Convert all files(.txt, .pdf) in the sub-directories of the given path to Documents that can be written to a

Document Store.

**Arguments**:

- `merge_lowercase`: allow conversion of merged paragraph to lowercase
- `merge_short`: allow merging of short paragraphs
- `dir_path`: path for the documents to be written to the DocumentStore
- `clean_func`: a custom cleaning function that gets applied to each doc (input: str, output:str)
- `split_paragraphs`: split text in paragraphs.
- `id_hash_keys`: Generate the document id from a custom list of strings that refer to the document's
attributes. If you want to ensure you don't have duplicate documents in your DocumentStore but texts are
not unique, you can modify the metadata and pass e.g. `"meta"` to this field (e.g. [`"content"`, `"meta"`]).
In this case the id will be generated by using the content and the defined metadata.

<a id="squad_data"></a>

# Module squad\_data

<a id="squad_data.SquadData"></a>

## SquadData

```python
class SquadData()
```

This class is designed to manipulate data that is in SQuAD format

<a id="squad_data.SquadData.__init__"></a>

#### SquadData.\_\_init\_\_

```python
def __init__(squad_data)
```

**Arguments**:

- `squad_data`: SQuAD format data, either as a dict with a `data` key, or just a list of SQuAD documents

<a id="squad_data.SquadData.merge_from_file"></a>

#### SquadData.merge\_from\_file

```python
def merge_from_file(filename: str)
```

Merge the contents of a SQuAD format json file with the data stored in this object

<a id="squad_data.SquadData.merge"></a>

#### SquadData.merge

```python
def merge(new_data: List)
```

Merge data in SQuAD format with the data stored in this object

**Arguments**:

- `new_data`: A list of SQuAD document data

<a id="squad_data.SquadData.from_file"></a>

#### SquadData.from\_file

```python
@classmethod
def from_file(cls, filename: str)
```

Create a SquadData object by providing the name of a SQuAD format json file

<a id="squad_data.SquadData.save"></a>

#### SquadData.save

```python
def save(filename: str)
```

Write the data stored in this object to a json file.

<a id="squad_data.SquadData.to_document_objs"></a>

#### SquadData.to\_document\_objs

```python
def to_document_objs()
```

Export all paragraphs stored in this object to haystack.Document objects.

<a id="squad_data.SquadData.to_label_objs"></a>

#### SquadData.to\_label\_objs

```python
def to_label_objs()
```

Export all labels stored in this object to haystack.Label objects.

<a id="squad_data.SquadData.to_df"></a>

#### SquadData.to\_df

```python
@staticmethod
def to_df(data)
```

Convert a list of SQuAD document dictionaries into a pandas dataframe (each row is one annotation)

<a id="squad_data.SquadData.count"></a>

#### SquadData.count

```python
def count(unit="questions")
```

Count the samples in the data. Choose from unit = "paragraphs", "questions", "answers", "no_answers", "span_answers"

<a id="squad_data.SquadData.df_to_data"></a>

#### SquadData.df\_to\_data

```python
@classmethod
def df_to_data(cls, df)
```

Convert a dataframe into SQuAD format data (list of SQuAD document dictionaries).

<a id="squad_data.SquadData.sample_questions"></a>

#### SquadData.sample\_questions

```python
def sample_questions(n)
```

Return a sample of n questions in SQuAD format (list of SQuAD document dictionaries)
Note, that if the same question is asked on multiple different passages, this fn treats that
as a single question

<a id="squad_data.SquadData.get_all_paragraphs"></a>

#### SquadData.get\_all\_paragraphs

```python
def get_all_paragraphs()
```

Return all paragraph strings.

<a id="squad_data.SquadData.get_all_questions"></a>

#### SquadData.get\_all\_questions

```python
def get_all_questions()
```

Return all question strings. Note that if the same question appears for different paragraphs, it will be
returned multiple times by this fn

<a id="squad_data.SquadData.get_all_document_titles"></a>

#### SquadData.get\_all\_document\_titles

```python
def get_all_document_titles()
```

Return all document title strings

